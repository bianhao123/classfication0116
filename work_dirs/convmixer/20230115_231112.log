2023-01-15 23:11:12,718 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu113
OpenCV: 4.1.2
MMCV: 1.5.0
MMCV Compiler: GCC 7.5
MMCV CUDA Compiler: 11.1
MMClassification: 0.25.0+48fdcdb
------------------------------------------------------------

2023-01-15 23:11:12,719 - mmcls - INFO - Distributed training: False
2023-01-15 23:11:12,840 - mmcls - INFO - Config:
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150])
runner = dict(type='EpochBasedRunner', max_epochs=150)
dataset_type = 'CustomDataset'
img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=False)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='Normalize',
        mean=[0, 0, 0],
        std=[255.0, 255.0, 255.0],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='Normalize',
        mean=[0, 0, 0],
        std=[255.0, 255.0, 255.0],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=128,
    workers_per_gpu=1,
    train=dict(
        type='CustomDataset',
        data_prefix='/data111/bianhao/code/xy/yinhe/myData64/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='Normalize',
                mean=[0, 0, 0],
                std=[255.0, 255.0, 255.0],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CustomDataset',
        data_prefix='/data111/bianhao/code/xy/yinhe/myData64/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='Normalize',
                mean=[0, 0, 0],
                std=[255.0, 255.0, 255.0],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CustomDataset',
        data_prefix='data/cifar10',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='Normalize',
                mean=[0, 0, 0],
                std=[255.0, 255.0, 255.0],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
checkpoint_config = dict(interval=10)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
root_path = '/data111/bianhao/code/xy/mmclassification'
evaluation = dict(
    interval=1, metric=['accuracy', 'precision', 'recall', 'f1_score'])
model = dict(
    type='ImageClassifier',
    backbone=dict(type='ConvMixer', arch='768/32', act_cfg=dict(type='ReLU')),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=9,
        in_channels=768,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0)))
work_dir = './work_dirs/convmixer'
gpu_ids = [0]

2023-01-15 23:11:12,841 - mmcls - INFO - Set random seed to 2132173976, deterministic: False
2023-01-15 23:11:13,157 - mmcls - INFO - initialize LinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}
Name of parameter - Initialization information

backbone.stem.0.weight - torch.Size([768, 3, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stem.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stem.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stem.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.4.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.5.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.6.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.7.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.8.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.9.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.10.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.11.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.12.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.13.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.14.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.15.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.16.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.17.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.18.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.19.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.20.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.21.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.22.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.23.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.24.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.25.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.26.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.27.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.28.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.29.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.30.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.0.fn.0.weight - torch.Size([768, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.0.fn.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.0.fn.2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.0.fn.2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.31.3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([9, 768]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([9]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-01-15 23:11:29,666 - mmcls - INFO - Start running, host: bianhao@server111, work_dir: /data111/bianhao/code/xy/mmclassification/work_dirs/convmixer
2023-01-15 23:11:29,666 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2023-01-15 23:11:29,667 - mmcls - INFO - workflow: [('train', 1)], max: 150 epochs
2023-01-15 23:11:29,667 - mmcls - INFO - Checkpoints will be saved to /data111/bianhao/code/xy/mmclassification/work_dirs/convmixer by HardDiskBackend.
2023-01-15 23:12:00,806 - mmcls - INFO - Epoch(val) [1][13]	accuracy_top-1: 14.7211, accuracy_top-5: 27.5616, precision: 7.0642, recall: 9.8200, f1_score: 3.8387
2023-01-15 23:12:32,236 - mmcls - INFO - Epoch(val) [2][13]	accuracy_top-1: 79.1829, accuracy_top-5: 97.0169, precision: 52.6216, recall: 53.5697, f1_score: 52.9697
2023-01-15 23:13:03,695 - mmcls - INFO - Epoch(val) [3][13]	accuracy_top-1: 81.1933, accuracy_top-5: 95.7847, precision: 66.7493, recall: 60.5636, f1_score: 60.8044
2023-01-15 23:13:41,720 - mmcls - INFO - Epoch(val) [4][13]	accuracy_top-1: 87.8729, accuracy_top-5: 98.2490, precision: 69.0486, recall: 62.7210, f1_score: 63.9651
2023-01-15 23:14:19,930 - mmcls - INFO - Epoch(val) [5][13]	accuracy_top-1: 85.8625, accuracy_top-5: 98.1193, precision: 63.0631, recall: 65.5132, f1_score: 62.7668
2023-01-15 23:14:58,053 - mmcls - INFO - Epoch(val) [6][13]	accuracy_top-1: 81.6472, accuracy_top-5: 97.5357, precision: 57.4392, recall: 51.6523, f1_score: 49.5986
2023-01-15 23:15:35,828 - mmcls - INFO - Epoch(val) [7][13]	accuracy_top-1: 89.5590, accuracy_top-5: 98.1842, precision: 66.9697, recall: 64.3397, f1_score: 65.3033
2023-01-15 23:16:13,448 - mmcls - INFO - Epoch(val) [8][13]	accuracy_top-1: 92.0233, accuracy_top-5: 98.8975, precision: 67.0509, recall: 70.6284, f1_score: 68.6701
2023-01-15 23:16:51,643 - mmcls - INFO - Epoch(val) [9][13]	accuracy_top-1: 92.8016, accuracy_top-5: 98.3787, precision: 75.9801, recall: 80.2862, f1_score: 77.4638
2023-01-15 23:17:25,551 - mmcls - INFO - Saving checkpoint at 10 epochs
2023-01-15 23:17:29,492 - mmcls - INFO - Epoch(val) [10][13]	accuracy_top-1: 94.3580, accuracy_top-5: 99.6109, precision: 77.3755, recall: 82.9620, f1_score: 79.3122
2023-01-15 23:18:08,239 - mmcls - INFO - Epoch(val) [11][13]	accuracy_top-1: 93.5798, accuracy_top-5: 98.8975, precision: 88.1648, recall: 75.6306, f1_score: 78.6712
2023-01-15 23:18:45,981 - mmcls - INFO - Epoch(val) [12][13]	accuracy_top-1: 94.2931, accuracy_top-5: 98.9624, precision: 86.9650, recall: 81.1549, f1_score: 83.3910
2023-01-15 23:19:23,761 - mmcls - INFO - Epoch(val) [13][13]	accuracy_top-1: 94.3580, accuracy_top-5: 99.3515, precision: 85.5172, recall: 84.3754, f1_score: 84.7982
2023-01-15 23:20:01,736 - mmcls - INFO - Epoch(val) [14][13]	accuracy_top-1: 94.0337, accuracy_top-5: 98.7030, precision: 82.3532, recall: 79.6440, f1_score: 80.0680
2023-01-15 23:20:40,287 - mmcls - INFO - Epoch(val) [15][13]	accuracy_top-1: 94.6174, accuracy_top-5: 99.2218, precision: 86.1139, recall: 81.3347, f1_score: 82.5321
2023-01-15 23:21:18,236 - mmcls - INFO - Epoch(val) [16][13]	accuracy_top-1: 95.8495, accuracy_top-5: 99.1569, precision: 89.3740, recall: 88.1944, f1_score: 88.7426
2023-01-15 23:21:55,667 - mmcls - INFO - Epoch(val) [17][13]	accuracy_top-1: 95.9792, accuracy_top-5: 99.1569, precision: 87.9474, recall: 89.8793, f1_score: 88.8278
2023-01-15 23:22:34,632 - mmcls - INFO - Epoch(val) [18][13]	accuracy_top-1: 96.0441, accuracy_top-5: 99.4163, precision: 93.0769, recall: 88.8459, f1_score: 90.4501
2023-01-15 23:23:12,051 - mmcls - INFO - Epoch(val) [19][13]	accuracy_top-1: 95.3956, accuracy_top-5: 99.3515, precision: 88.0327, recall: 84.6428, f1_score: 85.7848
2023-01-15 23:23:47,217 - mmcls - INFO - Saving checkpoint at 20 epochs
2023-01-15 23:23:50,669 - mmcls - INFO - Epoch(val) [20][13]	accuracy_top-1: 95.8495, accuracy_top-5: 99.4812, precision: 88.4169, recall: 88.6820, f1_score: 88.2943
2023-01-15 23:24:28,879 - mmcls - INFO - Epoch(val) [21][13]	accuracy_top-1: 95.2010, accuracy_top-5: 98.9624, precision: 83.2987, recall: 83.1985, f1_score: 83.2008
2023-01-15 23:25:06,720 - mmcls - INFO - Epoch(val) [22][13]	accuracy_top-1: 96.0441, accuracy_top-5: 99.4163, precision: 87.3914, recall: 86.9346, f1_score: 87.0832
2023-01-15 23:25:43,894 - mmcls - INFO - Epoch(val) [23][13]	accuracy_top-1: 94.7471, accuracy_top-5: 99.4163, precision: 83.7299, recall: 82.5148, f1_score: 82.8496
2023-01-15 23:26:22,872 - mmcls - INFO - Epoch(val) [24][13]	accuracy_top-1: 96.2387, accuracy_top-5: 99.3515, precision: 87.0085, recall: 88.3932, f1_score: 87.3585
2023-01-15 23:27:00,392 - mmcls - INFO - Epoch(val) [25][13]	accuracy_top-1: 96.6926, accuracy_top-5: 99.2218, precision: 91.2660, recall: 93.4361, f1_score: 92.1315
2023-01-15 23:27:37,492 - mmcls - INFO - Epoch(val) [26][13]	accuracy_top-1: 96.6278, accuracy_top-5: 99.4163, precision: 90.0803, recall: 90.9474, f1_score: 90.1901
2023-01-15 23:28:16,379 - mmcls - INFO - Epoch(val) [27][13]	accuracy_top-1: 93.7095, accuracy_top-5: 98.9624, precision: 91.5104, recall: 89.4905, f1_score: 89.4710
2023-01-15 23:28:53,476 - mmcls - INFO - Epoch(val) [28][13]	accuracy_top-1: 96.9520, accuracy_top-5: 99.5460, precision: 92.6660, recall: 97.0633, f1_score: 94.3891
2023-01-15 23:29:31,487 - mmcls - INFO - Epoch(val) [29][13]	accuracy_top-1: 96.6926, accuracy_top-5: 99.5460, precision: 93.4079, recall: 93.9105, f1_score: 93.6260
2023-01-15 23:30:06,408 - mmcls - INFO - Saving checkpoint at 30 epochs
2023-01-15 23:30:10,153 - mmcls - INFO - Epoch(val) [30][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.4812, precision: 92.7329, recall: 95.1169, f1_score: 93.8511
2023-01-15 23:30:47,684 - mmcls - INFO - Epoch(val) [31][13]	accuracy_top-1: 95.9144, accuracy_top-5: 99.4163, precision: 90.9346, recall: 91.8626, f1_score: 91.1889
2023-01-15 23:31:24,922 - mmcls - INFO - Epoch(val) [32][13]	accuracy_top-1: 96.3684, accuracy_top-5: 99.3515, precision: 93.5865, recall: 93.2897, f1_score: 93.2883
2023-01-15 23:32:03,779 - mmcls - INFO - Epoch(val) [33][13]	accuracy_top-1: 96.0441, accuracy_top-5: 99.2218, precision: 94.1510, recall: 93.5896, f1_score: 93.4528
2023-01-15 23:32:41,200 - mmcls - INFO - Epoch(val) [34][13]	accuracy_top-1: 96.1089, accuracy_top-5: 99.7406, precision: 96.1594, recall: 86.6173, f1_score: 87.7622
2023-01-15 23:33:19,287 - mmcls - INFO - Epoch(val) [35][13]	accuracy_top-1: 96.9520, accuracy_top-5: 99.4812, precision: 92.7463, recall: 94.3755, f1_score: 93.5135
2023-01-15 23:33:56,946 - mmcls - INFO - Epoch(val) [36][13]	accuracy_top-1: 97.2763, accuracy_top-5: 99.5460, precision: 96.0393, recall: 96.0987, f1_score: 95.8946
2023-01-15 23:34:34,936 - mmcls - INFO - Epoch(val) [37][13]	accuracy_top-1: 95.4604, accuracy_top-5: 99.6109, precision: 91.6162, recall: 92.4618, f1_score: 91.9509
2023-01-15 23:35:12,876 - mmcls - INFO - Epoch(val) [38][13]	accuracy_top-1: 95.9792, accuracy_top-5: 99.4163, precision: 90.7923, recall: 88.7692, f1_score: 89.0959
2023-01-15 23:35:51,128 - mmcls - INFO - Epoch(val) [39][13]	accuracy_top-1: 97.2114, accuracy_top-5: 99.8703, precision: 93.5391, recall: 93.6003, f1_score: 93.4875
2023-01-15 23:36:26,217 - mmcls - INFO - Saving checkpoint at 40 epochs
2023-01-15 23:36:29,732 - mmcls - INFO - Epoch(val) [40][13]	accuracy_top-1: 95.4604, accuracy_top-5: 99.5460, precision: 89.9728, recall: 87.6322, f1_score: 87.8110
2023-01-15 23:37:07,100 - mmcls - INFO - Epoch(val) [41][13]	accuracy_top-1: 97.1466, accuracy_top-5: 99.7406, precision: 96.1903, recall: 94.4860, f1_score: 95.0309
2023-01-15 23:37:45,623 - mmcls - INFO - Epoch(val) [42][13]	accuracy_top-1: 97.2763, accuracy_top-5: 99.6758, precision: 93.7551, recall: 95.4329, f1_score: 94.4876
2023-01-15 23:38:23,252 - mmcls - INFO - Epoch(val) [43][13]	accuracy_top-1: 96.8872, accuracy_top-5: 99.8703, precision: 93.3704, recall: 93.8441, f1_score: 93.3134
2023-01-15 23:39:01,016 - mmcls - INFO - Epoch(val) [44][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.5460, precision: 95.3824, recall: 92.8514, f1_score: 93.4045
2023-01-15 23:39:38,268 - mmcls - INFO - Epoch(val) [45][13]	accuracy_top-1: 96.6278, accuracy_top-5: 99.4812, precision: 89.9376, recall: 94.7705, f1_score: 91.8411
2023-01-15 23:40:16,793 - mmcls - INFO - Epoch(val) [46][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.4812, precision: 96.8365, recall: 94.5352, f1_score: 95.3979
2023-01-15 23:40:54,779 - mmcls - INFO - Epoch(val) [47][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.7406, precision: 93.7794, recall: 95.6211, f1_score: 94.6057
2023-01-15 23:41:32,817 - mmcls - INFO - Epoch(val) [48][13]	accuracy_top-1: 97.2114, accuracy_top-5: 99.5460, precision: 96.6260, recall: 94.5454, f1_score: 95.2956
2023-01-15 23:42:11,673 - mmcls - INFO - Epoch(val) [49][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.4812, precision: 96.0204, recall: 97.9433, f1_score: 96.9175
2023-01-15 23:42:45,578 - mmcls - INFO - Saving checkpoint at 50 epochs
2023-01-15 23:42:49,535 - mmcls - INFO - Epoch(val) [50][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6109, precision: 95.5582, recall: 96.4212, f1_score: 95.9710
2023-01-15 23:43:27,691 - mmcls - INFO - Epoch(val) [51][13]	accuracy_top-1: 97.5357, accuracy_top-5: 99.3515, precision: 93.1362, recall: 97.8020, f1_score: 95.0018
2023-01-15 23:44:06,033 - mmcls - INFO - Epoch(val) [52][13]	accuracy_top-1: 97.5357, accuracy_top-5: 99.4163, precision: 93.2529, recall: 95.9653, f1_score: 94.4825
2023-01-15 23:44:44,008 - mmcls - INFO - Epoch(val) [53][13]	accuracy_top-1: 97.4060, accuracy_top-5: 99.4812, precision: 92.8021, recall: 94.0669, f1_score: 93.3819
2023-01-15 23:45:20,811 - mmcls - INFO - Epoch(val) [54][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.5460, precision: 97.6384, recall: 95.0361, f1_score: 96.0688
2023-01-15 23:45:59,723 - mmcls - INFO - Epoch(val) [55][13]	accuracy_top-1: 97.4708, accuracy_top-5: 99.4163, precision: 94.6391, recall: 97.5694, f1_score: 95.9275
2023-01-15 23:46:37,172 - mmcls - INFO - Epoch(val) [56][13]	accuracy_top-1: 96.3684, accuracy_top-5: 99.5460, precision: 92.7782, recall: 96.9622, f1_score: 94.6235
2023-01-15 23:47:14,724 - mmcls - INFO - Epoch(val) [57][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.6109, precision: 91.9185, recall: 92.4519, f1_score: 91.7935
2023-01-15 23:47:53,621 - mmcls - INFO - Epoch(val) [58][13]	accuracy_top-1: 97.5357, accuracy_top-5: 99.8055, precision: 93.0407, recall: 96.3807, f1_score: 94.5504
2023-01-15 23:48:31,044 - mmcls - INFO - Epoch(val) [59][13]	accuracy_top-1: 96.4981, accuracy_top-5: 99.6109, precision: 90.9723, recall: 96.2787, f1_score: 92.9644
2023-01-15 23:49:05,549 - mmcls - INFO - Saving checkpoint at 60 epochs
2023-01-15 23:49:09,451 - mmcls - INFO - Epoch(val) [60][13]	accuracy_top-1: 93.1258, accuracy_top-5: 99.1569, precision: 84.4778, recall: 81.2585, f1_score: 82.0032
2023-01-15 23:49:47,735 - mmcls - INFO - Epoch(val) [61][13]	accuracy_top-1: 96.5629, accuracy_top-5: 99.6758, precision: 93.7428, recall: 90.6366, f1_score: 91.6699
2023-01-15 23:50:25,686 - mmcls - INFO - Epoch(val) [62][13]	accuracy_top-1: 94.6822, accuracy_top-5: 99.6109, precision: 90.2382, recall: 88.9114, f1_score: 89.2667
2023-01-15 23:51:02,389 - mmcls - INFO - Epoch(val) [63][13]	accuracy_top-1: 96.2387, accuracy_top-5: 99.6758, precision: 94.7623, recall: 89.1943, f1_score: 89.6079
2023-01-15 23:51:41,170 - mmcls - INFO - Epoch(val) [64][13]	accuracy_top-1: 96.1089, accuracy_top-5: 99.6758, precision: 93.9546, recall: 95.4012, f1_score: 94.4321
2023-01-15 23:52:18,515 - mmcls - INFO - Epoch(val) [65][13]	accuracy_top-1: 97.3411, accuracy_top-5: 99.6758, precision: 94.8213, recall: 97.5196, f1_score: 96.0724
2023-01-15 23:52:56,392 - mmcls - INFO - Epoch(val) [66][13]	accuracy_top-1: 96.7575, accuracy_top-5: 99.5460, precision: 94.8583, recall: 88.8150, f1_score: 89.5709
2023-01-15 23:53:34,743 - mmcls - INFO - Epoch(val) [67][13]	accuracy_top-1: 96.7575, accuracy_top-5: 99.7406, precision: 91.8134, recall: 96.7727, f1_score: 93.6961
2023-01-15 23:54:12,824 - mmcls - INFO - Epoch(val) [68][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.6109, precision: 97.4659, recall: 97.9710, f1_score: 97.6996
2023-01-15 23:54:50,516 - mmcls - INFO - Epoch(val) [69][13]	accuracy_top-1: 96.8872, accuracy_top-5: 99.5460, precision: 92.9322, recall: 95.1322, f1_score: 93.8685
2023-01-15 23:55:25,462 - mmcls - INFO - Saving checkpoint at 70 epochs
2023-01-15 23:55:29,426 - mmcls - INFO - Epoch(val) [70][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.4812, precision: 91.8652, recall: 92.7148, f1_score: 91.8602
2023-01-15 23:56:07,666 - mmcls - INFO - Epoch(val) [71][13]	accuracy_top-1: 96.7575, accuracy_top-5: 99.8703, precision: 95.9314, recall: 92.4100, f1_score: 93.4602
2023-01-15 23:56:44,931 - mmcls - INFO - Epoch(val) [72][13]	accuracy_top-1: 96.9520, accuracy_top-5: 99.4812, precision: 88.6774, recall: 93.5654, f1_score: 90.6337
2023-01-15 23:57:22,819 - mmcls - INFO - Epoch(val) [73][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.6758, precision: 94.9113, recall: 94.7985, f1_score: 94.7713
2023-01-15 23:58:00,835 - mmcls - INFO - Epoch(val) [74][13]	accuracy_top-1: 97.2763, accuracy_top-5: 99.6109, precision: 93.1776, recall: 97.1426, f1_score: 94.8366
2023-01-15 23:58:38,950 - mmcls - INFO - Epoch(val) [75][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.6109, precision: 93.2129, recall: 97.9714, f1_score: 95.2384
2023-01-15 23:59:16,800 - mmcls - INFO - Epoch(val) [76][13]	accuracy_top-1: 97.3411, accuracy_top-5: 99.6109, precision: 90.2651, recall: 97.1046, f1_score: 92.8348
2023-01-15 23:59:55,489 - mmcls - INFO - Epoch(val) [77][13]	accuracy_top-1: 96.6278, accuracy_top-5: 99.4812, precision: 97.1125, recall: 93.6329, f1_score: 95.0859
2023-01-16 00:00:33,003 - mmcls - INFO - Epoch(val) [78][13]	accuracy_top-1: 97.0169, accuracy_top-5: 99.8055, precision: 96.2054, recall: 88.9964, f1_score: 90.3749
2023-01-16 00:01:10,982 - mmcls - INFO - Epoch(val) [79][13]	accuracy_top-1: 97.2763, accuracy_top-5: 99.6109, precision: 95.0450, recall: 97.6125, f1_score: 96.1608
2023-01-16 00:01:46,446 - mmcls - INFO - Saving checkpoint at 80 epochs
2023-01-16 00:01:50,294 - mmcls - INFO - Epoch(val) [80][13]	accuracy_top-1: 96.8223, accuracy_top-5: 99.7406, precision: 85.5936, recall: 86.2038, f1_score: 85.8760
2023-01-16 00:02:27,587 - mmcls - INFO - Epoch(val) [81][13]	accuracy_top-1: 97.1466, accuracy_top-5: 99.7406, precision: 94.5359, recall: 94.1971, f1_score: 94.2270
2023-01-16 00:03:04,847 - mmcls - INFO - Epoch(val) [82][13]	accuracy_top-1: 96.8872, accuracy_top-5: 99.4812, precision: 89.6087, recall: 95.2927, f1_score: 90.7355
2023-01-16 00:03:42,903 - mmcls - INFO - Epoch(val) [83][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6109, precision: 95.1446, recall: 97.7252, f1_score: 96.1243
2023-01-16 00:04:21,007 - mmcls - INFO - Epoch(val) [84][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.5460, precision: 93.0031, recall: 97.7073, f1_score: 94.4123
2023-01-16 00:04:58,273 - mmcls - INFO - Epoch(val) [85][13]	accuracy_top-1: 97.5357, accuracy_top-5: 99.6758, precision: 94.2263, recall: 94.8016, f1_score: 94.4848
2023-01-16 00:05:36,998 - mmcls - INFO - Epoch(val) [86][13]	accuracy_top-1: 97.0817, accuracy_top-5: 99.6758, precision: 93.7418, recall: 94.0394, f1_score: 93.8384
2023-01-16 00:06:14,373 - mmcls - INFO - Epoch(val) [87][13]	accuracy_top-1: 96.6278, accuracy_top-5: 99.4812, precision: 89.4113, recall: 91.5369, f1_score: 90.0996
2023-01-16 00:06:52,398 - mmcls - INFO - Epoch(val) [88][13]	accuracy_top-1: 95.9144, accuracy_top-5: 99.4812, precision: 87.5845, recall: 94.1950, f1_score: 88.7660
2023-01-16 00:07:31,234 - mmcls - INFO - Epoch(val) [89][13]	accuracy_top-1: 97.2114, accuracy_top-5: 99.4812, precision: 94.5078, recall: 95.9168, f1_score: 95.1556
2023-01-16 00:08:04,927 - mmcls - INFO - Saving checkpoint at 90 epochs
2023-01-16 00:08:08,832 - mmcls - INFO - Epoch(val) [90][13]	accuracy_top-1: 97.4708, accuracy_top-5: 99.6109, precision: 91.6946, recall: 95.9069, f1_score: 93.4467
2023-01-16 00:08:45,904 - mmcls - INFO - Epoch(val) [91][13]	accuracy_top-1: 96.8223, accuracy_top-5: 99.6109, precision: 91.8033, recall: 95.3172, f1_score: 93.1250
2023-01-16 00:09:23,881 - mmcls - INFO - Epoch(val) [92][13]	accuracy_top-1: 96.1738, accuracy_top-5: 99.6758, precision: 91.6117, recall: 95.1227, f1_score: 92.7843
2023-01-16 00:10:02,043 - mmcls - INFO - Epoch(val) [93][13]	accuracy_top-1: 96.7575, accuracy_top-5: 99.5460, precision: 92.9630, recall: 91.6705, f1_score: 91.8764
2023-01-16 00:10:39,383 - mmcls - INFO - Epoch(val) [94][13]	accuracy_top-1: 97.2763, accuracy_top-5: 99.3515, precision: 94.8718, recall: 95.8819, f1_score: 95.3074
2023-01-16 00:11:18,003 - mmcls - INFO - Epoch(val) [95][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.3515, precision: 91.9782, recall: 97.6642, f1_score: 94.1908
2023-01-16 00:11:55,647 - mmcls - INFO - Epoch(val) [96][13]	accuracy_top-1: 97.4060, accuracy_top-5: 99.3515, precision: 95.7484, recall: 97.6305, f1_score: 96.6127
2023-01-16 00:12:33,683 - mmcls - INFO - Epoch(val) [97][13]	accuracy_top-1: 97.4060, accuracy_top-5: 99.5460, precision: 96.2226, recall: 96.0632, f1_score: 96.1296
2023-01-16 00:13:11,930 - mmcls - INFO - Epoch(val) [98][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.7406, precision: 96.7316, recall: 96.4427, f1_score: 96.5799
2023-01-16 00:13:50,347 - mmcls - INFO - Epoch(val) [99][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.5460, precision: 96.1844, recall: 96.6610, f1_score: 96.4067
2023-01-16 00:14:24,664 - mmcls - INFO - Saving checkpoint at 100 epochs
2023-01-16 00:14:28,037 - mmcls - INFO - Epoch(val) [100][13]	accuracy_top-1: 97.7302, accuracy_top-5: 99.5460, precision: 94.8967, recall: 96.1666, f1_score: 95.4687
2023-01-16 00:15:05,884 - mmcls - INFO - Epoch(val) [101][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.5460, precision: 95.8223, recall: 96.6414, f1_score: 96.2173
2023-01-16 00:15:44,772 - mmcls - INFO - Epoch(val) [102][13]	accuracy_top-1: 98.0545, accuracy_top-5: 99.6109, precision: 96.8758, recall: 96.6678, f1_score: 96.7672
2023-01-16 00:16:22,219 - mmcls - INFO - Epoch(val) [103][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.6109, precision: 95.5983, recall: 96.4165, f1_score: 95.9901
2023-01-16 00:17:00,098 - mmcls - INFO - Epoch(val) [104][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.4163, precision: 94.5443, recall: 96.2740, f1_score: 95.2724
2023-01-16 00:17:38,274 - mmcls - INFO - Epoch(val) [105][13]	accuracy_top-1: 97.7302, accuracy_top-5: 99.5460, precision: 96.4379, recall: 96.4003, f1_score: 96.4135
2023-01-16 00:18:16,014 - mmcls - INFO - Epoch(val) [106][13]	accuracy_top-1: 97.7302, accuracy_top-5: 99.5460, precision: 95.1221, recall: 96.2831, f1_score: 95.6535
2023-01-16 00:18:53,566 - mmcls - INFO - Epoch(val) [107][13]	accuracy_top-1: 98.0545, accuracy_top-5: 99.4163, precision: 96.7150, recall: 96.7295, f1_score: 96.7208
2023-01-16 00:19:32,390 - mmcls - INFO - Epoch(val) [108][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.6109, precision: 96.5736, recall: 96.4461, f1_score: 96.5044
2023-01-16 00:20:09,715 - mmcls - INFO - Epoch(val) [109][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.4163, precision: 96.6129, recall: 96.5275, f1_score: 96.5664
2023-01-16 00:20:44,000 - mmcls - INFO - Saving checkpoint at 110 epochs
2023-01-16 00:20:47,809 - mmcls - INFO - Epoch(val) [110][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.5460, precision: 96.6415, recall: 96.5668, f1_score: 96.5992
2023-01-16 00:21:26,707 - mmcls - INFO - Epoch(val) [111][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.4163, precision: 96.0006, recall: 96.3075, f1_score: 96.1305
2023-01-16 00:22:04,144 - mmcls - INFO - Epoch(val) [112][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.5460, precision: 94.7401, recall: 96.6250, f1_score: 95.6285
2023-01-16 00:22:41,999 - mmcls - INFO - Epoch(val) [113][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.6109, precision: 95.9658, recall: 96.5861, f1_score: 96.2603
2023-01-16 00:23:20,222 - mmcls - INFO - Epoch(val) [114][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.4812, precision: 95.4851, recall: 96.6333, f1_score: 96.0164
2023-01-16 00:23:58,067 - mmcls - INFO - Epoch(val) [115][13]	accuracy_top-1: 98.0545, accuracy_top-5: 99.5460, precision: 96.0086, recall: 96.6871, f1_score: 96.3334
2023-01-16 00:24:35,349 - mmcls - INFO - Epoch(val) [116][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.4163, precision: 94.9480, recall: 96.5240, f1_score: 95.6784
2023-01-16 00:25:14,108 - mmcls - INFO - Epoch(val) [117][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.6109, precision: 94.8891, recall: 96.4230, f1_score: 95.5972
2023-01-16 00:25:51,211 - mmcls - INFO - Epoch(val) [118][13]	accuracy_top-1: 98.0545, accuracy_top-5: 99.4812, precision: 96.0333, recall: 96.7278, f1_score: 96.3667
2023-01-16 00:26:28,640 - mmcls - INFO - Epoch(val) [119][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.6109, precision: 96.0583, recall: 96.6203, f1_score: 96.3224
2023-01-16 00:27:04,148 - mmcls - INFO - Saving checkpoint at 120 epochs
2023-01-16 00:27:07,842 - mmcls - INFO - Epoch(val) [120][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6758, precision: 95.8976, recall: 96.4310, f1_score: 96.1439
2023-01-16 00:27:46,037 - mmcls - INFO - Epoch(val) [121][13]	accuracy_top-1: 97.4060, accuracy_top-5: 99.5460, precision: 95.7019, recall: 96.2679, f1_score: 95.9616
2023-01-16 00:28:23,884 - mmcls - INFO - Epoch(val) [122][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.6758, precision: 95.8976, recall: 96.4962, f1_score: 96.1788
2023-01-16 00:29:02,199 - mmcls - INFO - Epoch(val) [123][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.6758, precision: 96.0689, recall: 96.5582, f1_score: 96.2966
2023-01-16 00:29:40,545 - mmcls - INFO - Epoch(val) [124][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6758, precision: 95.9264, recall: 96.3952, f1_score: 96.1413
2023-01-16 00:30:18,028 - mmcls - INFO - Epoch(val) [125][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.8055, precision: 95.9147, recall: 96.4376, f1_score: 96.1569
2023-01-16 00:30:56,632 - mmcls - INFO - Epoch(val) [126][13]	accuracy_top-1: 97.4708, accuracy_top-5: 99.7406, precision: 95.7708, recall: 96.1704, f1_score: 95.9470
2023-01-16 00:31:34,723 - mmcls - INFO - Epoch(val) [127][13]	accuracy_top-1: 97.5357, accuracy_top-5: 99.6109, precision: 93.7009, recall: 96.3249, f1_score: 94.9011
2023-01-16 00:32:11,989 - mmcls - INFO - Epoch(val) [128][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.4812, precision: 94.7808, recall: 96.4325, f1_score: 95.3641
2023-01-16 00:32:49,816 - mmcls - INFO - Epoch(val) [129][13]	accuracy_top-1: 97.7302, accuracy_top-5: 99.4812, precision: 95.4895, recall: 96.4963, f1_score: 95.9750
2023-01-16 00:33:25,246 - mmcls - INFO - Saving checkpoint at 130 epochs
2023-01-16 00:33:29,273 - mmcls - INFO - Epoch(val) [130][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.4812, precision: 94.4703, recall: 96.5339, f1_score: 95.4378
2023-01-16 00:34:06,705 - mmcls - INFO - Epoch(val) [131][13]	accuracy_top-1: 97.4060, accuracy_top-5: 99.6109, precision: 93.8365, recall: 96.1635, f1_score: 94.9380
2023-01-16 00:34:44,787 - mmcls - INFO - Epoch(val) [132][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6758, precision: 94.5276, recall: 96.2959, f1_score: 95.3533
2023-01-16 00:35:23,596 - mmcls - INFO - Epoch(val) [133][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.6758, precision: 95.6785, recall: 96.2959, f1_score: 95.9692
2023-01-16 00:36:00,936 - mmcls - INFO - Epoch(val) [134][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.7406, precision: 95.9041, recall: 96.6465, f1_score: 96.2600
2023-01-16 00:36:38,735 - mmcls - INFO - Epoch(val) [135][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.7406, precision: 95.8260, recall: 96.5845, f1_score: 96.1892
2023-01-16 00:37:17,049 - mmcls - INFO - Epoch(val) [136][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.7406, precision: 96.9236, recall: 96.5259, f1_score: 96.6403
2023-01-16 00:37:54,419 - mmcls - INFO - Epoch(val) [137][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.6758, precision: 96.1166, recall: 96.5651, f1_score: 96.3217
2023-01-16 00:38:31,719 - mmcls - INFO - Epoch(val) [138][13]	accuracy_top-1: 98.1193, accuracy_top-5: 99.6758, precision: 96.0037, recall: 96.7102, f1_score: 96.3431
2023-01-16 00:39:10,610 - mmcls - INFO - Epoch(val) [139][13]	accuracy_top-1: 98.1193, accuracy_top-5: 99.7406, precision: 98.0903, recall: 98.2599, f1_score: 98.1693
2023-01-16 00:39:44,489 - mmcls - INFO - Saving checkpoint at 140 epochs
2023-01-16 00:39:48,510 - mmcls - INFO - Epoch(val) [140][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.6758, precision: 97.2649, recall: 96.5896, f1_score: 96.8470
2023-01-16 00:40:26,483 - mmcls - INFO - Epoch(val) [141][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.7406, precision: 95.9941, recall: 96.5617, f1_score: 96.2606
2023-01-16 00:41:05,316 - mmcls - INFO - Epoch(val) [142][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.6109, precision: 95.5885, recall: 96.5244, f1_score: 96.0359
2023-01-16 00:41:43,263 - mmcls - INFO - Epoch(val) [143][13]	accuracy_top-1: 97.9896, accuracy_top-5: 99.6758, precision: 96.1698, recall: 96.6237, f1_score: 96.3786
2023-01-16 00:42:21,130 - mmcls - INFO - Epoch(val) [144][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.6758, precision: 96.5183, recall: 96.6286, f1_score: 96.5709
2023-01-16 00:42:59,363 - mmcls - INFO - Epoch(val) [145][13]	accuracy_top-1: 97.6005, accuracy_top-5: 99.6109, precision: 93.8192, recall: 96.2407, f1_score: 94.8836
2023-01-16 00:43:37,408 - mmcls - INFO - Epoch(val) [146][13]	accuracy_top-1: 97.7951, accuracy_top-5: 99.6758, precision: 95.1060, recall: 96.3241, f1_score: 95.6638
2023-01-16 00:44:14,377 - mmcls - INFO - Epoch(val) [147][13]	accuracy_top-1: 97.7302, accuracy_top-5: 99.6758, precision: 94.3695, recall: 96.3841, f1_score: 95.2375
2023-01-16 00:44:53,219 - mmcls - INFO - Epoch(val) [148][13]	accuracy_top-1: 97.9248, accuracy_top-5: 99.6758, precision: 95.1914, recall: 96.4675, f1_score: 95.7818
2023-01-16 00:45:30,752 - mmcls - INFO - Epoch(val) [149][13]	accuracy_top-1: 97.6654, accuracy_top-5: 99.6109, precision: 94.9729, recall: 96.2978, f1_score: 95.5840
2023-01-16 00:46:05,379 - mmcls - INFO - Saving checkpoint at 150 epochs
2023-01-16 00:46:09,284 - mmcls - INFO - Epoch(val) [150][13]	accuracy_top-1: 97.8599, accuracy_top-5: 99.6109, precision: 95.1198, recall: 96.4447, f1_score: 95.7330
